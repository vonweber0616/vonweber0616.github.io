<!DOCTYPE html>
<html>

<head><meta name="generator" content="Hexo 3.8.0">
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<meta name="theme-color" content="#33474d">
	<title>Von Weber&#39;s Blog</title>
	<link rel="stylesheet" href="/css/style.css">
	
      <link rel="alternate" href="/atom.xml" title="Von Weber&#39;s Blog" type="application/atom+xml">
	
	
	<script type="text/x-mathjax-config">
		MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
	</script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML" async></script>

</head>

<body>

	<header class="header">
		<nav class="header__nav">
			
				<a href="/archives" class="header__link">Archive</a>
			
				<a href="/tags" class="header__link">Tags</a>
			
				<a href="/atom.xml" class="header__link">RSS</a>
			
		</nav>
		<h1 class="header__title"><a href="/">Von Weber&#39;s Blog</a></h1>
		<h2 class="header__subtitle">No models are correct, but some are more elegant than others.</h2>
	</header>

	<main>
		



	<article>
	
		<h1><a href="/2018/11/23/Saddlepoint-Approximation/">Saddlepoint Approximation</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2018-11-23</span><br>
		
		
			<span class="article__tags">
			  	<a class="article__tag-link" href="/tags/积分计算/">积分计算</a> <a class="article__tag-link" href="/tags/统计/">统计</a> <a class="article__tag-link" href="/tags/统计计算/">统计计算</a>
			</span>
		
	</div>

	

	
		<p>和Edgeworth展开相比，鞍点近似是更加精细的分布近似方法，鞍点近似同时适用于连续和离散的分布。在许多极端的条件下，鞍点近似都表现出惊人的精度。鞍点近似有许多角度的理解，然而下面的推导展示了鞍点近似和Edgeworth的关系，以及它为什么具有高精度。</p>
<h2 id="Tilted-Exponential-Families"><a href="#Tilted-Exponential-Families" class="headerlink" title="Tilted Exponential Families"></a>Tilted Exponential Families</h2><p>设 $f(x)$ 是一个密度函数，在区间 $(a,b)$ 具有矩母函数 $M(s) = E e^{sX} $ 和累量母函数 $ K(s) = \log M(s) $。则下列指数分布族称为 tilted 正则指数族 $$ f(x;s) = \exp \{ sx - K(s) \} f(x), \qquad s \in (a,b) $$<br>$f(x;s)$ 称作 s-tilted 密度，用 $X_s$ 表示服从此密度的一个随机变量。容易推导 $X_s$ 的 均值和方差满足<br>$$ E(X_s) = K’(s)$$ $$ Var(X_s) = K’’(s)$$<br>以及 $X_s$ 的高阶标准化累量<br>$$ \kappa_i(s) = E \left( {X_s -\mu_s \over \sigma_s} \right)^i =<br>{K^{(i)}(s) \over \{ K’’(s) \}^{i/2} }, \qquad i \geq 3 $$</p>
<h2 id="Saddlepoint-Approximation"><a href="#Saddlepoint-Approximation" class="headerlink" title="Saddlepoint Approximation"></a>Saddlepoint Approximation</h2><p>由 tilted 指数族定义可知<br>$$ f(x) \equiv \exp \{ K(s) -sx \} f(x;s), \qquad \forall s \in (a,b) $$<br>注意这里是对任意的 s，两边都是一样的密度函数。所以我们可以针对不同的 x，选择不同的 s，使近似效果达到最佳。</p>
<p>考虑 $ f(x;s) $ 的Edgeworth 展开<br>$$ f(x;s) = \phi \left( {x -\mu_s \over \sigma_s} \right) \left\{ 1 + {\kappa_{3}(s) \over 6 }  \left[ \left( {x -\mu_s \over \sigma_s} \right)^3 - 3 \left( {x -\mu_s \over \sigma_s} \right)  \right] + O \left( {1 \over n} \right) \right\} $$<br>对于固定的 x，若选择s，使得 $\mu_s =x$，则在x点上的近似具有 $O(1/n)$ 的精度。现在对不同的x，我们始终选择 $\hat s$ 满足<br>$$  K’(\hat s(x)) = x $$<br>从而可以使 $o(1/n)$ 的精度是全局的。上面的方程被称作鞍点方程。将 $ f(x;s) $ 的近似带入到 $ f(x) $ 中<br>$$ f(x) \approx {1 \over \sqrt{2 \pi K’’(\hat s (x)) }} \exp \{ K(\hat s(x)) -\hat s(x)x \} $$<br>上式称为 $ f(x) $ 的（一阶）鞍点近似。</p>
<h2 id="连续分布的鞍点近似"><a href="#连续分布的鞍点近似" class="headerlink" title="连续分布的鞍点近似"></a>连续分布的鞍点近似</h2><p>设 $X_i, i \in \Bbb{N}$ 是独立同分布的连续随机变量，具有累量母函数 $K(s)$。则均值 $ \bar X =\sum_{i=1}^n X_i$ 密度函数的鞍点近似为<br>$$ \hat f _{\bar X}(x)  = \sqrt{ { n \over 2 \pi K’’(\hat s (x)) } } \exp \{ K( \hat s(x)) -\hat s(x)x \} $$</p>
<p>$X$ 分布的函数的鞍点近似为<br>$$ \hat F_{\bar X}(x) = \begin{cases}<br>    \Phi(\hat w) + \phi(\hat w) \left( {1 \over \hat w} - {1 \over \hat u} \right) &amp; \text{if  }x \neq \mu \\<br>    {1 \over 2} + { K’’’(0) \over 6 \sqrt{2} \pi K’’(0)^{3/2} } &amp; \text{if  }x = \mu<br>\end{cases} $$<br>其中<br>$$\begin{align}<br>\hat w &amp;= \text{sgn}(\hat s) \sqrt{ 2 \{ \hat s x -K(\hat s) \} } \\<br>\hat u &amp;= \hat s \sqrt{ K’’(\hat s) }<br>\end{align} $$<br>$\Phi(\cdot),\phi(\cdot) $ 分别为标准正态分布的分布和桉树和密度函数，$\hat s$ 是鞍点方程 $K’(s) =x $ 的解。</p>
<h2 id="离散分布的鞍点近似"><a href="#离散分布的鞍点近似" class="headerlink" title="离散分布的鞍点近似"></a>离散分布的鞍点近似</h2><p>设 $X$ 是整数 $\Bbb{Z}$ 上的随机变量， $p(k)$ 是其质量函数，则 $p(k) $ 具有鞍点近似<br>$$ \hat p(k) = {1 \over \sqrt{ 2 \pi K’’(\hat s) }} \exp \{  K(\hat s) - \hat s k  \} $$<br>其中 $\hat s$ 是鞍点方程 $K’(\hat s) = k, \quad k \in \mathcal{I_X}  $， $\mathcal{I_X}  $ 是 supp X 延展的内点集。</p>
<p>定义 $ k^- =k-1/2 \in \mathcal{I_X} $ 是 k的偏置，$\hat s$ 是鞍点方程 $K’(\hat s) = k^-$ 的解，则$X$ 生存函数的（第二连续性矫正）鞍点近似为<br>$$ \hat{Pr}(X \geq k) = \begin{cases}<br>    1 - \Phi(\hat w) - \phi(w)(1/2 - 1/u) &amp; \text{if } k^- \neq \mu \\<br>    1/2 - { K’’’(0) \over 6 \sqrt{2} K’’(0)^{3/2} } &amp; \text{if  } k^- = \mu<br>\end{cases}  $$<br>其中<br>$$\begin{align}<br>    \hat w &amp;= \text{sgn}(\hat s) \sqrt{2 \{ \hat s k^- -K(\hat s)  \}} \\<br>    \hat u &amp;= 2 \text{sinh}(\hat s/2) \sqrt{K’’(\hat s)}<br>\end{align}$$</p>

	

	

</article>




	<article>
	
		<h1><a href="/2018/11/22/Edgeworth-Expansion/">Edgeworth Expansion</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2018-11-22</span><br>
		
		
			<span class="article__tags">
			  	<a class="article__tag-link" href="/tags/积分计算/">积分计算</a> <a class="article__tag-link" href="/tags/统计/">统计</a> <a class="article__tag-link" href="/tags/统计计算/">统计计算</a>
			</span>
		
	</div>

	

	
		<p>许多时候，我们感兴趣的随机变量 $X$ 具有复杂的结构，我们无法或者很难得到它的精确分布密度PDF或分布函数CDF，对于 $X$ 的研究比如求概率 $P(X \in A)$ 就变得不那么直接。多数情况下，$X$ 可以表示为一些独立甚至同分布随机变量的和（均值）。对于平凡的问题，我们可以利用中心极限定理CLT将 $X$ 的分布近似为正态分布。然而对于一些问题比如</p>
<ul>
<li>$\bar X={1 \over n} \sum_{i=1}^n X_i$，n很小只有几或者几十</li>
<li>$P(\bar X \in A)$ 很小比如 $P(\sqrt{n}|\bar X -\mu| &gt; 4\sigma)$ </li>
</ul>
<p>此时正态分布的近似就很差。而Edgeworth展开作为中心极限定理的自然延伸，从一定程度上改善了近似的效果</p>
<h2 id="Tchebycheff–Hermite-Polynomials"><a href="#Tchebycheff–Hermite-Polynomials" class="headerlink" title="Tchebycheff–Hermite Polynomials"></a>Tchebycheff–Hermite Polynomials</h2><p>设 $\phi(z)$ 是标准正态分布 $N(0,1)$ 的密度函数，由归纳法容易证明，存在多项式 $ \{H(z) \}_k$ 成立<br>$${ d^k \over dz^k} \phi (z) = (-1)^k H_k(z) \phi (z) $$<br>其中 $\{ H_k(z): k \in \Bbb{N} \}$ 称为Tchebycheff–Hermite多项式。对上式求导，得到<br>$${d \over dx} [ H_k(z)\phi(z) ]=-H_{k+1}(z)\phi(z) $$<br>由此可以递推出 $H_k(z)$，前几项为<br>$$\begin{align}<br>    H_0(z) &amp;=1 &amp; H_3(z)&amp;= z^3 − 3z  \\<br>    H_1 (z) &amp;= z  &amp; H_4 (z) &amp;= z^4 − 6z^2 + 3 \\<br>    H_2 (z) &amp;= z^2 − 1 &amp; H_5 (z) &amp;= z^5 − 10z^3 + 15z<br>\end{align}$$</p>
<p>$\{ H_k(z): k \in \Bbb{N} \}$ 是正交多项式，在如下的加权內积意义下<br>$$&lt;H_i(z), H_j(z)&gt; = \int_{\Bbb{R} }H_i (z) H_j (z)\phi (z)dz=<br>\begin{cases}<br>    0 &amp; \text{if }i\neq j \\<br>    i! &amp; \text{if } i=j<br>\end{cases}$$</p>
<h2 id="Inverse-Fourier-Transform"><a href="#Inverse-Fourier-Transform" class="headerlink" title="Inverse Fourier Transform"></a>Inverse Fourier Transform</h2><p>设 $X \sim g(x)$ 具有特征函数 $h(u)$，则 $h(u)$ 具有逆变换<br>$$g(x)={1 \over 2\pi } \int_{\Bbb{R}} e^{-iux} h(u)du$$<br>特别地，由Fourier变换的性质，成立<br>$$\begin{align}<br>{1 \over 2\pi } \int_{\Bbb{R}} e^{-iux} e^{-u^2/2} (iu)^k du<br>&amp;= {(-1)^k \over 2 \pi} {d^k \over dx^k} \int_{\Bbb{R}} e^{-iux} e^{-u^2/2}du \\<br>&amp;= (-1)^k {d^k \over dx^k} \phi(x) \\<br>&amp;= H_k(x)\phi(x)<br>\end{align}$$<br>也就是说若 $X$ 具有特征函数 $e^{-u^2/2} (iu)^k$，则 $X$ 具有密度函数 $H_k(x)\phi(x)$。</p>
<h2 id="Edgeworth-Expansion-的推导"><a href="#Edgeworth-Expansion-的推导" class="headerlink" title="Edgeworth Expansion 的推导"></a>Edgeworth Expansion 的推导</h2><p>设 $X_i$ 有均值0方差1，有有限四阶矩，记 $\gamma=E X_j^3, \tau=E X_j^4$。现在考虑正规化均值 $S_n = \sqrt{n} \bar X$ 的特征函数。<br>$$h_{S_n} (u)=E \exp \{ ( iu/ \sqrt{n} ) \sum X_j \} =[ h_X(u/\sqrt{n}) ]^n$$<br>对 $\exp \{ iuX/\sqrt{n} \}$ 作泰勒展开得到<br>$$h_X \left( {u \over \sqrt{n}} \right) = E e^ { iu {X \over \sqrt{n}} }<br>= \left( 1- {u^2 \over 2n} \right) +<br>{(iu)^3 \gamma \over 6n \sqrt{n} } +<br>{(iu)^4 \tau \over 24n^2 } +<br>o \left( {1 \over n^2} \right)$$<br>两边取n次幂，再由二项展开式和<br>$$ \left( 1+ {a \over n} \right) ^{n-k} =<br>e^a \left( 1- {a(a+k) \over 2n} \right) +<br>o \left( {1 \over n} \right)$$<br>得到<br>$$h_{S_n}(u) = e^{-u^2/2} \left[ 1 +<br>{(iu)^3 \gamma \over 6 \sqrt{n} } +<br>{(iu)^4 ( \tau -3) \over 24n } +<br>{(iu)^6 \gamma^2 \over 72n} \right] +<br>o \left( {1 \over n} \right)$$<br>最后由上述关于特征函数和密度函数的逆变换，得到 $S_n$ 的密度函数为<br>$$\begin{align}<br>g_{S_n}(x) &amp;= {1 \over 2\pi } \int_{\Bbb{R}} e^{-iux} h_{S_n}(u) du \\<br>&amp;= \phi(x) \left( 1+<br>{1 \over \sqrt{n}} {\gamma H_3(x) \over 6} +<br>{1 \over n} \left[ {(\tau-3) H_4(x) \over 24} +<br>{\gamma^2 H_5(x) \over 72} \right] \right) +<br>o \left( {1 \over n} \right)<br>\end{align}$$<br>两边求积分，利用上面 $H_k(x) \phi(x)$ 的递推关系得到 $S_n$ 分布函数的近似<br>$$G_{S_n}(x)=<br>\Phi(x) - \phi(x) \left(<br>{1 \over \sqrt{n}} {\gamma H_2(x) \over 6} +<br>{1 \over n} \left[ {(\tau-3) H_3(x) \over 24} +<br>{\gamma^2 H_4(x) \over 72} \right] \right) +<br>o \left( {1 \over n} \right)<br>$$<br>包含上述 $1/\sqrt{n}$ 和 $ 1/n$ 的近似，分别叫做Edgeworth一阶/二阶展开。</p>
<p>此外值得一提的是</p>
<ul>
<li>若 $X_i$ 具有对称分布，三阶矩 $\gamma=0$，通常的正态分布近似已经具有一阶Edgeworth近似的精度，</li>
<li>$g_{S_n}(x)$ 在0点（非正规化的随机变量在均值 $\mu$ 点），由于奇数Hermite多项式在0点为0，即 $H_3(0)=0$，故一阶Edgeworth近似具有 $O(1/n)$ 的精度，</li>
<li>Edgeworth展开并未进行概率意义上的规约，所以计算结果可能超出 $[0,1]$ 之外。</li>
<li>高阶的Edgeworth展开虽然具有理论上的高阶渐进精度，但也容易矫枉过正，使结果不可靠，因而仅具有理论意义。</li>
</ul>
<h2 id="指数分布的和"><a href="#指数分布的和" class="headerlink" title="指数分布的和"></a>指数分布的和</h2><p>设 $X_i \sim \text{Exp}(1),i=1,…,5$ 则 $\mu = \sigma^2=1, E(X_i-\mu)^3/\sigma^3 = 2, E(X_i-\mu)^4/\sigma^4 = 6$。现在考虑 $X_i$ 的正规化和 $S_n = \sqrt{n} (\bar X -\mu)$ 的分布，由于 $\sum X_i \sim \Gamma(5,1)$，我们可以准确知道 $S_n$ 的分布。下面的代码和图1展示了正态分布和Edgeworth近似的效果。</p>
<pre><code class="R">n = <span class="number">5</span>
b1 = <span class="number">2</span>
b2 = <span class="number">6</span>
H3 = <span class="keyword">function</span>(x) (x ^ <span class="number">3</span> - <span class="number">3</span> * x)
H4 = <span class="keyword">function</span>(x) (x ^ <span class="number">4</span> - <span class="number">6</span> * x ^ <span class="number">2</span> + <span class="number">3</span>)
H6 = <span class="keyword">function</span>(x)  (x ^ <span class="number">6</span> - <span class="number">15</span> * x ^ <span class="number">4</span> + <span class="number">45</span> * x ^ <span class="number">2</span> - <span class="number">15</span>)

f1 = <span class="keyword">function</span>(x) {
  dnorm(x) * (<span class="number">1</span> + b1 * H3(x) / <span class="number">6</span> / sqrt(n))
}

f2 = <span class="keyword">function</span>(x) {
  f1(x) + (b2 * H4(x) / <span class="number">24</span> / n + b1 ^ <span class="number">2</span> * H6(x) / <span class="number">72</span> / n) * dnorm(x)
}
x = seq(-<span class="number">3</span>, <span class="number">3</span>, <span class="number">0.01</span>)
fn_true = dgamma((x + sqrt(n)) * sqrt(n), n, <span class="number">1</span>) * sqrt(n)
fn_E0 = dnorm(x)
fn_E1 = f1(x)
fn_E2 = f2(x)
label = c(<span class="string">'Exact'</span>,
          <span class="string">'Normal'</span>,
          <span class="string">'First-order Edgeworth'</span>,
          <span class="string">'Second-order Edgeworth'</span>)
data = data.frame(
  density = c(fn_true, fn_E0, fn_E1, fn_E2),
  x = rep(x, <span class="number">4</span>),
  estimate = rep(label, each = length(x))
)
ggplot(data, aes(x, density, color = estimate)) +
  scale_colour_manual(breaks = label,
                      values = c(<span class="string">'#000000'</span>, <span class="string">'#1b9e77'</span>,  <span class="string">'#d95f02'</span>, <span class="string">'#7570b3'</span>)) +
  theme(legend.position = c(<span class="number">0.85</span>, <span class="number">0.82</span>)) +
  geom_line()
</code></pre>
<p><figure class="figure"><img src="/img/Edgeworth-1.svg" alt="图1. 指数分布和的Edgeworth近似"><figcaption class="figure__caption">图1. 指数分布和的Edgeworth近似</figcaption></figure></p>
<p>由上图可以看出</p>
<ul>
<li>正态分布的近似效果极差，由于样本量太小，无法纠正指数分布的偏度</li>
<li>Edgeworth近似在分布的主体部分有不错的近似效果</li>
<li>在分布的尾部，Edgeworth的效果的仍不好，甚至在左尾出现了负值</li>
</ul>
<p>下面的表格展示了一些区间概率的估计，印证了上面的论断</p>
<table>
<thead>
<tr>
<th>$(a,b)$</th>
<th>正态分布</th>
<th>一阶Edgeworth近似</th>
<th>二阶Edgeworth近似</th>
<th>精确值</th>
</tr>
</thead>
<tbody>
<tr>
<td>$(-\infty,-2.0)$</td>
<td>0.023</td>
<td>-0.001</td>
<td>-0.007</td>
<td>0.000</td>
</tr>
<tr>
<td>$(-\infty,-1.8)$</td>
<td>0.036</td>
<td>0.010</td>
<td>0.000</td>
<td>0.003</td>
</tr>
<tr>
<td>$(-\infty,-1.6)$</td>
<td>0.055</td>
<td>0.029</td>
<td>0.017</td>
<td>0.015</td>
</tr>
<tr>
<td>$(-0.2，0.2)$</td>
<td>0.158</td>
<td>0.158</td>
<td>0.156</td>
<td>0.156</td>
</tr>
<tr>
<td>$(-1.0,1.0)$</td>
<td>0.682</td>
<td>0.682</td>
<td>0.698</td>
<td>0.700</td>
</tr>
<tr>
<td>$(1.8,\infty)$</td>
<td>0.036</td>
<td>0.062</td>
<td>0.053</td>
<td>0.054</td>
</tr>
<tr>
<td>$(2.0,\infty)$</td>
<td>0.023</td>
<td>0.047</td>
<td>0.041</td>
<td>0.041</td>
</tr>
</tbody>
</table>

	

	

</article>




	<article>
	
		<h1><a href="/2018/11/20/Laplace-Approximation/">Laplace Approximation</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2018-11-20</span><br>
		
		
			<span class="article__tags">
			  	<a class="article__tag-link" href="/tags/积分计算/">积分计算</a> <a class="article__tag-link" href="/tags/统计/">统计</a> <a class="article__tag-link" href="/tags/统计计算/">统计计算</a>
			</span>
		
	</div>

	

	
		<p>统计中的计算问题大致可以分成两类，积分问题和最优化问题，积分问题常常和Bayes方法有关，最优化问题常常和似然方法相关。求积分的方法，除了基于模拟的Monte Carlo方法外，也有一些基于分析的方法在统计中常见，其中最古老也最有用的方法就是Laplace近似。</p>
<p>假设我们感兴趣的积分问题是<br>$$\int_A f(x|\theta) dx$$<br>其中 $f$ 是非负可积函数，$\theta$ 是固定的参数。</p>
<p>将被积函数写作 $f(x|\theta)=\exp \{ nh(x|\theta) \}$，其中n是样本大小或者某个可以趋近无穷大的参数，对 $h(x|\theta)$ 在 $x_0$ 点作Taylor展开，得到<br>$$h(x|\theta) =<br>h(x_0|\theta)+(x-x_0)h’(x_0|\theta)+{(x-x_0)^2 \over 2!} h’’(x_0|\theta)+<br>{(x-x_0)^3 \over 3!} h’’’(x_0|\theta) + R_n(x)$$<br>其中 $R_n(x) = o((x-x_0)^3), x \to x_0.$</p>
<p>现在选择 $x_0=\hat x_{\theta}$，满足 $h’(x_0|\theta)=0$ 且最大化 $h(x|\theta)$。在 $\hat x_{\theta}$ 的某个邻域成立<br>$$\int_A e^{nh(x|\theta)} dx \approx e^{nh(\hat x_{\theta}|\theta)} \int_A<br>e^{n {(x-x_0)^2 \over 2!} h’’(\hat x_{\theta}|\theta)}<br>e^{n {(x-x_0)^3 \over 3!} h’’’(\hat x_{\theta}|\theta)}$$<br>对于三阶导项，若考虑指数展开 $e^y \approx 1+y+y^2/{2!}$ ，得到近似<br>$$e^{n {(x-x_0)^3 \over 3!} h’’’(\hat x_{\theta}|\theta)} \approx<br>1+ n {(x-x_0)^3 \over 3!} h’’’(\hat x_{\theta}|\theta)+<br>n^2 {(x-x_0)^6 \over {2! (3!)^2 }} [ h’’’(\hat x_{\theta}|\theta) ]^2$$</p>
<p>带回去，我们得到<br>$$\int_A e^{nh(x|\theta)} dx \approx<br>e^{nh(\hat x_{\theta}|\theta)} \int_A<br>e^{n {(x-x_0)^2 \over 2!} h’’(\hat x_{\theta}|\theta)} \times<br>\left[ 1+ n {(x-x_0)^3 \over 3!} h’’’(\hat x_{\theta}|\theta)+<br>n^2 {(x-x_0)^6 \over {2! (3!)^2 }} [ h’’’(\hat x_{\theta}|\theta) ]^2 \right] dx$$<br>上式方括号内分别取前1/2/3项，分别叫做一阶/二阶/三阶Laplace近似。</p>
<p>特别地，对于一阶近似，注意到其和正态分布密度的关系，我们可以将其表示为<br>$$\int_A e^{nh(x|\theta)} dx \approx<br>e^{nh(\hat x_{\theta}|\theta)}<br>\sqrt{2 \pi \over {-n h’’(\hat x_{\theta}|\theta)}} \times<br>\left \{ \Phi [ \sqrt{-n h’’(\hat x_{\theta}|\theta)} (b- \hat x_{\theta}) ] -<br>\Phi [ \sqrt{-n h’’(\hat x_{\theta}|\theta)} (a- \hat x_{\theta}) ]\right \} $$<br>其中，取 $A=[ a,b ]$，$\Phi(\cdot)$ 为标准正态分布的cdf。</p>
<p>从上面的形式可以看出，Laplace近似的计算不存在本质困难，但二三阶近似的计算略显繁琐。</p>
<h3 id="Gamma积分的近似"><a href="#Gamma积分的近似" class="headerlink" title="Gamma积分的近似"></a>Gamma积分的近似</h3><p>若以一例来说明Laplace近似的功效，我们考虑Gamma分布 $\mathcal{G}a(\alpha, 1/ \beta)$ 的积分<br>$$\int_a^b {x^{\alpha-1} \over {\Gamma (\alpha) \beta^\alpha}} e^{-x/ \beta} dx$$</p>
<p>略去分母的常数，首先求得 $h(x) = - {x \over \beta} +(\alpha-1) \log(x)$，一二三阶导数分别为<br>$$\begin{align}<br>    h’(x) &amp;= {\alpha -1 \over x}- {1 \over \beta} \\<br>    h’’(x) &amp;= - {\alpha-1 \over x^2} \\<br>    h’’’(x) &amp;= {2(\alpha-1) \over x^3}<br>\end{align}$$<br>对于 $\alpha=5, \beta=2$，选取 $\hat x_\theta = (\alpha-1)\beta=8$。对于不同的积分区间，计算Laplace近似，得到下表</p>
<table>
<thead>
<tr>
<th>区间</th>
<th>一阶近似</th>
<th>二阶近似</th>
<th>三阶近似</th>
<th>精确值</th>
</tr>
</thead>
<tbody>
<tr>
<td>(7,9)</td>
<td>0.193351</td>
<td>0.193351</td>
<td>0.193351</td>
<td>0.193341</td>
</tr>
<tr>
<td>(6,10)</td>
<td>0.375046</td>
<td>0.375046</td>
<td>0.375057</td>
<td>0.374770</td>
</tr>
<tr>
<td>(2,14)</td>
<td>0.848559</td>
<td>0.848559</td>
<td>0.859839</td>
<td>0.823349</td>
</tr>
<tr>
<td>(0,7)</td>
<td>0.370755</td>
<td>0.293452</td>
<td>0.315920</td>
<td>0.274555</td>
</tr>
<tr>
<td>(15.987,$\infty$)</td>
<td>0.022454</td>
<td>0.075564</td>
<td>0.155272</td>
<td>0.100005</td>
</tr>
</tbody>
</table>
<p>由此可以看出，对于一般的包含的 $\hat x_\theta$ 的区间，Laplace近似效果不错，尤其的关于 $\hat x_\theta$ 对称的区间，由于二阶近似等于一阶近似，一阶近似的值已经相当精确。但是对于偏离 $\hat x_\theta$ 的区间，近似的偏差较大，对于尾概率的估计更是难以接受。相较于费时的Monte Carlo方法，快捷的Laplace近似可以看作最终解决方案的一个指导。</p>

	

	

</article>




	<article>
	
		<h1><a href="/2018/11/05/ARS-Adaptive-Rejection-Sampling/">ARS (Adaptive Rejection Sampling)</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2018-11-05</span><br>
		
		
			<span class="article__tags">
			  	<a class="article__tag-link" href="/tags/C/">C</a> <a class="article__tag-link" href="/tags/统计/">统计</a> <a class="article__tag-link" href="/tags/统计计算/">统计计算</a> <a class="article__tag-link" href="/tags/随机数产生/">随机数产生</a>
			</span>
		
	</div>

	

	
		<p>ARS (Adaptive Rejection Sampling) 是一种生成具有对数凹密度 (log-concave density)的随机数的方法，ARS使用包围的接受拒绝 (Envelope Accept-Reject) 方法，而Envelope接受拒绝方法是一般接受拒绝方法的一个变形（改进）。</p>
<h2 id="Envelope-Accept-Reject"><a href="#Envelope-Accept-Reject" class="headerlink" title="Envelope Accept-Reject"></a>Envelope Accept-Reject</h2><p>和普通的接受拒绝方法相比，EAR多了一个下界，即，若存在密度$g_m$，函数$g_l$和正常数$M$满足<br>$$g_l(x) \leq f(x) \leq Mg_m(x),$$<br>则下列算法产生随机变量服从分布$f$</p>
<ol>
<li>生成 $X \sim g_m(x), U \sim \mathcal{U}_{[0,1]}$</li>
<li>IF  $U \leq g_l(X)/Mg_m(X)$</li>
<li>THEN 接受$X$</li>
<li>ELSEIF  $U \leq f(X)/Mg_m(X)$</li>
<li>THEN 接受$X$</li>
</ol>
<p>这个算法的成立是显然的，若有$U \leq g_l(X)/Mg_m(X)$，必有$U \leq f(X)/Mg_m(X)$，所以和普通的接受拒绝方法相比，EAR可能在第3行就结束，而不用计算$f(x)$的值，这个优点当$f(x)$很难计算时便很有用。</p>
<p>当然EAR并不能完全避免计算$f(x)$的值，具体来讲，节省的比例为<br>$$\begin{align}<br>P(U \leq g_l(X)/Mg_m(x)) &amp;= E[P(U \leq g_l(X)/Mg_m(X) | X)] \\<br>                         &amp;= E[g_l(X)/Mg_m(X)] \\<br>                         &amp;= \frac{1}{M} \int{g_m(x)dx}<br>\end{align}$$</p>
<p>值得一提的是，上述的函数$g_l, f, g_m$，都可以之多差一个系数，但是这样的话，常数$M$不再具有上述的含义。以正态分布$N(0,1)$为例，略去常数，取 $f(x)=\exp (-x^2/2)$。由泰勒公式，<br>$$e^{-x^2/2} \geq 1-\frac{x^2}{2}$$<br>于是可取<br>$$g_l(x) = \left (1-\frac{x^2}{2} \right ) \lor 0$$<br>另一方面若取$g_m(x)$为Laplace(1)分布，即$g_m(x)=\lambda /2 \exp (-\lambda x), \lambda=1$，则容易计算接受率为76%，引入Envelope下界，可避免58%的$f(x)$的计算，对于复杂的目标密度，这个节省还是很可观。</p>
<h2 id="Adaptive-Rejection-Sampling"><a href="#Adaptive-Rejection-Sampling" class="headerlink" title="Adaptive Rejection Sampling"></a>Adaptive Rejection Sampling</h2><p>自适应拒绝采样(ARS)的想法很简单，基于上述EAR的思路，对于具有对数凹密度的随机变量，由凹函数的几何性质，很容易构造出自适应的Envelope上下界，准确来讲是构造分段线性函数的上下界。</p>
<p><figure class="figure"><img src="/img/ARS.svg" alt="图 1. ARS算法"><figcaption class="figure__caption">图 1. ARS算法</figcaption></figure></p>
<p>如上图所示，设 $h=\log f$ 凹，$S_n = \{x_i, i=0,1,…,n+1\}$ 是一列从小到大的 $f$ 支撑上的点。由 $h$ 的凹性，直线 $L_{i,i+1}$ 穿过点 $(x_i,h(x_i))$ 和点 $(x_{i+1},h(x_{i+1}))$，在区间 $[x_i,x_{i+1}]$ 上在 $h$ 的下方，在这个区间外在 $h$ 的上方，于是我们定义<br>$$ \overline{h}_n (x) = \min \{ L_{i-1,i}(x), L_{i+1,i+2}(x) \}$$</p>
<p>如上图红线，定义<br>$$\underline{h}_n(x) = L_{i,i+1}(x)$$</p>
<p>如上图蓝线所示。在集合 $[ x_0,x_{n+1} ]^c$ 上补充<br>$$\underline{h}_n(x) = - \infty, \quad \overline{h}_n (x) = \min \{ L_{0,1}(x), L_{n,n+1}(x)$$<br>这样，在 $f$ 的支撑上成立<br>$$\underline{h}_n(x) \leq h(x) \leq \overline{h}_n (x)$$<br>最后取指数，即 $\underline{f}_n(x) = \exp \underline{h}_n(x)$，$\overline{f}_n(x) = \exp \overline{h}_n(x)$，有<br>$$\underline{f}_n(x) \leq f(x) \leq \overline{f}_n (x)= \varpi g_n(x)$$<br>最右边的等号表示，将 $\overline{f}_n(x)$ 归一化为密度函数，$\varpi$是正规化常数。</p>
<p>这样我们得到了Envelope的上下界，带入到EAR算法中，我们得到如下的ARS算法</p>
<ol start="0">
<li>初始化 $n$ 和 $S_n$</li>
<li>生成 $X \sim g_n(x), U \sim \mathcal{U}_{[ 0,1 ]}$</li>
<li>IF $U \leq \underline{f}_n(X) / \varpi g_n(X)$</li>
<li>THEN 接受 $X$</li>
<li>ELSEIF $U \leq f(X) / \varpi g_n(X)$</li>
<li>THEN 接受 $X$</li>
<li>$\qquad$更新 $S_n \to S_{n+1}=S_n \cup \{ X \}$</li>
</ol>
<p>ARS算法在生成随机数过程中会不断更新 $S_n$，使得Envelope上下界越来越接近 $f$，算法的效率越来越高，体现在接受率越来越接近1,和计算 $f(x)$ 的频率越来越少（趋近于0）。</p>
<p>另外要指出的是，算法中的常数 $\varpi$ 并不用计算，因为 $\varpi$ 总是和 $g_n(X)$ 一起，而 $\varpi g_n(X) = \overline{f}_n (x)$。</p>
<p>到此为止，ARS算法只差的步骤1的生成 $X \sim g_n(X)$，它被解决如下</p>
<h2 id="Generate-X-sim-g-n-x"><a href="#Generate-X-sim-g-n-x" class="headerlink" title="Generate $X \sim g_n(x)$"></a>Generate $X \sim g_n(x)$</h2><p>$g_n(x)$ 是分段函数，我们将它重新写成<br>$$g_n(x) = \varpi^{-1} \left \{ \sum_{i=0}^{r_n} e^{\alpha_i x + \beta_i} \Bbb{I}_{[ x_i,x_{i+1} ]}(x) +<br>e^{\alpha_{-1} x + \beta_{-1}} \Bbb{I}_{[- \infty,x_0]}(x) +<br>e^{\alpha_{r_n+1} x + \beta_{r_n+1}} \Bbb{I}_{[x_n+1,+ \infty]}(x) \right \}$$</p>
<p>其中 $y=\alpha_i x + \beta_i$ 对应区间 $[ x_i,x_i+1 ]$，这其中包括相邻两个线段的交点，直线 $y=\alpha_i x + \beta_i$ 和 $y=\alpha_{i+1} x + \beta_{i+1}$ 的交点在 $x=-(\beta_{i+1}-\beta_i)/(\alpha_{i+1}-\alpha_i)$ 处。$y=\alpha_{-1} x + \beta_{-1}$ 和 $y=\alpha_{r_n+1} x + \beta_{r_n+1}$ 分别对应区间 $[- \infty, x_0]$ 和 $ [ x_{n+1}, + \infty ]$， $r_n$ 表示线段的数量</p>
<p>由 $\varpi g_n(X) = \overline{f}_n (x)$，两边积分可得<br>$$\begin{align} \varpi_n &amp;= \int_{- \infty}^{x_0} e^{\alpha_{-1} x + \beta_{-1}} dx +<br>\sum_{i=0}^{r_n} \int_{x_i}^{x_{i+1}} e^{\alpha_{i} x + \beta_{i+1}} dx +<br>\int_{x_{n+1}}^{+ \infty} e^{\alpha_{r_n+1} x + \beta_{r_n+1}} dx \\<br>&amp;= \frac{e^{\alpha_{-1} x_0 + \beta_{-1}}}{\alpha_{-1}} +<br>\sum_{i=0}^{r_n}  e^{\beta_i} \frac{\alpha_{i} x_{i+1} - \alpha_{i} x_{i}}{\alpha_{i}} -<br>\frac{\alpha_{r_n+1} x_{n+1}}{\alpha_{r_n+1}}<br>\end{align}$$</p>
<p>由上面的计算知道，$g_n(x)$ 在区间 $[ x_i,x_{i+1} ]$ 上的概率<br>$$\omega_i = \begin{cases}<br>\frac{e^{\alpha_{-1} x_0 + \beta_{-1}}}{ \varpi \alpha_{-1}} &amp;\text{if } i=-1, \\<br>e^{\beta_i} \frac{\alpha_{i} x_{i+1} - \alpha_{i} x_{i}}{\varpi \alpha_{i}} &amp;\text{if } 0 \leq i \leq r_n, \\<br>-\frac{\alpha_{r_n+1} x_{n+1}}{\varpi \alpha_{r_n+1}} &amp;\text{if } i = r_n+1.<br>\end{cases}$$</p>
<p>其中 $ x_{-1}=- \infty, x_{r_n+2}=+ \infty$。利用逆分布分布函数方法，注意到若 $ X \sim g_n(x)$，则 $X|x_i \leq X \leq x_{i+1} \sim h(x)=c^{-1} \exp \{ \alpha_i x +\beta_i \} $，其中 $ c=\alpha^{-1} ( e^{\alpha_i x_{i+1} +\beta_i} -e^{\alpha_i x_{i} +\beta_i} )$，我们得到如下的算法生成随机变量 $X \sim g_n(x)$</p>
<ol>
<li>依概率 $\omega_i$ 选择区间 $[ x_i,x_{i+1} ]$ </li>
<li>生成 $U \sim \mathcal{U}_{[ 0,1 ]}$，取<br>$$ X = \alpha^{-1} \log [ e^{\alpha_i x_i} + U (e^{\alpha_i x_{i+1}} - e^{\alpha_i x_i}) ]$$</li>
</ol>
<h2 id="ARS算法的C语言实现"><a href="#ARS算法的C语言实现" class="headerlink" title="ARS算法的C语言实现"></a>ARS算法的C语言实现</h2><p>基于上述描述，我们用C语言实现ARS算法，由于算法中涉及许多动态动态内存的操作，考虑到结构化和性能的平衡，我们设计程序的结构如下。</p>
<p>首先是保存一个线段的结构 <code>Segment</code>，包含线段的始末横坐标，斜率，截距和取完指数后的积分。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> </span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="keyword">float</span> x1, x2;</span><br><span class="line">    <span class="keyword">float</span> alpha, beta;</span><br><span class="line">    <span class="keyword">float</span> area;</span><br><span class="line">&#125; Segment;</span><br></pre></td></tr></table></figure></p>
<p>结构体<code>Interval</code>保存了区间 $[ x_i, x_{i+1} ]$ 上的envelope上下界，包含下界一段和上界（至多）两段线段的信息。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="keyword">double</span> x1, x2;</span><br><span class="line">    <span class="keyword">double</span> alpha, beta;</span><br><span class="line">    Position flag;</span><br><span class="line">    Segment leftseg, rightseg;</span><br><span class="line">&#125; Interval;</span><br></pre></td></tr></table></figure></p>
<p>最后我们使用二叉搜索树来组织这些<code>Interval</code>，节点的序关系由区间的前后定义。二叉树的实现使得对分段函数的查找和求值达到 $O(\log n)$ 的时间复杂度。</p>
<p>生成随机数的函数<code>rars()</code>接受一个指向求密度函数对数的函数指针<code>(*log_density)(double)</code> ，不同的函数指针可以包装成不同的随机数函数。</p>
<p>下面的显示了部分核心代码，完整的源代码参见 <a href="https://github.com/vonweber0616/ARS" target="_blank" rel="noopener">GitHub仓库</a>。</p>
<p>最后值得一提的是ARS的算法我觉得唯一的优点就是泛用性，因为许多有用的分布都是对数凹密度。ARS算法看起来很理想，但是在实现上的缺点是它包含大量动态内存操作，这些内存操作的开销已经远超过计算本身，此外由于ARS算法构造分段的envelope上下界，随着集合 $S_n$ 不断增大，对分段函数进行求值得开销也越来越大。所以我觉得不如一开始就设定一个充分大的集合 $S_n$，比如包含几百个分割点，无需在生成随机数过程中更新 $S_n$。</p>
<script src="//gist.github.com/141a5cb0e9229491c07b3442ae5bd841.js?file=ARS.c"></script>

	

	

</article>





	<span class="different-posts">📖 <a href="/page/2">more posts</a> 📖</span>



	</main>

	<footer class="footer">
	<div class="footer-content">
		
	      <div class="footer__element">
	<p>Hi there, <br>welcome to my Blog glad you found it. Have a look around, will you?</p>
</div>

	    
	      <div class="footer__element">
	<h5>Check out</h5>
	<ul class="footer-links">
		<li class="footer-links__link"><a href="/archives">Archive</a></li>
		
		  <li class="footer-links__link"><a href="/atom.xml">RSS</a></li>
	    
		<li class="footer-links__link"><a href="/about">about page</a></li>
		<li class="footer-links__link"><a href="/tags">Tags</a></li>
		<li class="footer-links__link"><a href="/categories">Categories</a></li>
	</ul>
</div>

	    

		<div class="footer-credit">
			<span>© 2018 von Weber | Powered by <a href="https://hexo.io/">Hexo</a> | Theme <a href="https://github.com/HoverBaum/meilidu-hexo">MeiliDu</a></span>
		</div>

	</div>


</footer>



</body>

</html>
