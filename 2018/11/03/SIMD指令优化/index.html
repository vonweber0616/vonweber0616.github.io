<!DOCTYPE html>
<html>

<head><meta name="generator" content="Hexo 3.8.0">
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<meta name="theme-color" content="#33474d">
	<title>SIMD指令优化 | Von Weber&#39;s Blog</title>
	<link rel="stylesheet" href="/css/style.css">
	
      <link rel="alternate" href="/atom.xml" title="Von Weber&#39;s Blog" type="application/atom+xml">
	
	
	<script type="text/x-mathjax-config">
		MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
	</script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML" async></script>

	
		<!-- Highlight.js -->
		<link rel="stylesheet" href="//cdn.bootcss.com/highlight.js/9.2.0/styles/github.min.css">
		<script src="//cdn.bootcss.com/highlight.js/9.2.0/highlight.min.js">
		</script>
		<script> hljs.initHighlightingOnLoad();
		</script>
	

</head>

<body>

	<header class="header">
		<nav class="header__nav">
			
				<a href="/archives" class="header__link">Archive</a>
			
				<a href="/tags" class="header__link">Tags</a>
			
				<a href="/atom.xml" class="header__link">RSS</a>
			
		</nav>
		<h1 class="header__title"><a href="/">Von Weber&#39;s Blog</a></h1>
		<h2 class="header__subtitle"></h2>
	</header>

	<main>
		<article>
	
		<h1>SIMD指令优化</h1>
	
	<div class="article__infos">
		<span class="article__date">2018-11-03</span><br>
		
		
			<span class="article__tags">
			  	<a class="article__tag-link" href="/tags/AVX2/">AVX2</a> <a class="article__tag-link" href="/tags/C/">C</a> <a class="article__tag-link" href="/tags/SIMD/">SIMD</a> <a class="article__tag-link" href="/tags/汇编/">汇编</a>
			</span>
		
	</div>

	

	
		<p>本文介绍利用SIMD指令（AVX2）优化运算的一点探索，以单精度float类型的加法和乘法为例。</p>
<p>计算模型：</p>
<ul>
<li>hardware: E5 2678 v3 2.5GHz; X99; DDR4 2133 MHz 16GB x1</li>
<li>software: win10 17134; mingw-W64(gcc) 8.1.0</li>
</ul>
<h2 id="SIMD和AVX2简介"><a href="#SIMD和AVX2简介" class="headerlink" title="SIMD和AVX2简介"></a>SIMD和AVX2简介</h2><p>SIMD (<strong>s</strong>ingle <strong>i</strong>nstrucion <strong>m</strong>ultiple <strong>d</strong>ata)单指令多数据是用来对多个数据执行单个指令（算术或逻辑）的向量化方法，是X86-64(AMD64)指令集的拓展。由最早的SSE（SSE有多个改进版本，最后的SSE版本是SSE4.2），到后来的AVX，AVX2，最新的是AVX512，由于AVX512在较新和高端的CPU才支持，相较而言，更多的CPU支持AVX2。</p>
<p>AVX2指令集配合16个256位ymm寄存器（低128位为xmm寄存器），可以存储8个4字节(float, int)或4个8字节(double, long)数据，并在一个指令内同时做8个或4个运算。</p>
<h2 id="Naive-Solution"><a href="#Naive-Solution" class="headerlink" title="Naive Solution"></a>Naive Solution</h2><p>现在来考虑一个任务，将长度均为<code>N = 100000</code>的float数组<code>a, b, c</code>做运算<code>(a + b) * c</code>，存放在数组c中。将这个操作重复<code>NTIME = 50000</code>次，记录消耗的时间。</p>
<p>由于这个任务作为编程问题是如此的简单和直接，我们很快写出c程序如<code>code 0: simd0.c</code>，并觉得毫无优化的余地，因为仅有三行代码没有任何多余的操作，只有17,19,20三行代码是在完成任务。其中的变量<code>sum</code>仅仅是用来防止编译器的自动优化会直接去掉重复50000次这个步骤，虽然这个优化很厉害，但是偏离了我们的原意。</p>
<p>使用命令<code>gcc simd0.c -o simd0.exe</code>编译，运行时间为<code>13s 803ms 846μs</code>，取5次计算的中位数，下同。如果我们满足于这个结果，觉得已经很快了，那生活也就没有了乐趣。</p>
<p><code>`</code>c code 0: simd0.c</p>
<p>#include &lt;sys/time.h&gt;</p>
<p>#include &lt;stdio.h&gt;</p>
<p>#define N 100000</p>
<p>#define NTIMES 50000</p>
<p>float a[N], b[N], c[N], r[N];</p>
<p>int main(void)<br>{<br>    int i, times, sum;<br>    struct timeval starttime, endtime;<br>    long s, ms, us, timeuse;<br>    gettimeofday(&amp;starttime, 0);</p>
<pre><code>/* workhorse code  */
for (times = 0; times &lt; NTIMES; times++)
{
    for (i = 0; i &lt; N; ++i)
        r[i] = (a[i] + b[i]) * c[i];
    sum += sum;
}

/* elapsed time  */
gettimeofday(&amp;endtime, 0);
timeuse = 1000000 * (endtime.tv_sec - starttime.tv_sec) + 
        endtime.tv_usec - starttime.tv_usec;
s = timeuse / 1000000;
ms = timeuse / 1000 % 1000;
us = timeuse % 1000;
printf(&quot;%ld s %ld ms %ld us\n&quot;, s, ms, us);

return sum;
</code></pre><p>}</p>
<pre><code>## GCC自动优化
我们可以用命令`gcc -S -o simd0.s simd0.c`生成上述程序`simd0.exe`的汇编代码，看看哪里可以优化，其实这个汇编的蠢不在于没有用SIMD指令，主要问题是有太多的访问内存指令，代码没有贴出来。

如果我们使用`-O1`参数进行优化，即`gcc -O1 -o simd0-O1.exe simd0.c`，消耗的时间下降为`3s 841ms 346μs`。汇编代码如`code 1: simd0-O1.s`, 其中略去了计时，打印和某些伪指令，下同。
```x86asm code 1: simd0-O1.s
main:
  movl $50000, %edx
  jmp .L2
.L6:
  addss %xmm1, %xmm1
  subl $1, %edx
  je .L4
.L2:
  movl $0, %eax
.L3:
  movss a(%rax), %xmm0
  addss b(%rax), %xmm0
  mulss c(%rax), %xmm0
  movss %xmm0, r(%rax)
  addq $4, %rax
  cmpq $400000, %rax
  jne .L3
  jmp .L6
.L4:
  cvttss2si %xmm1, %eax
  ret
</code></pre><p><code>simd0-O1.s</code>的代码和不使用优化的代码相比，主要改进是从内存中取一个数比如<code>a[i]</code>，只需要一次访存，因为指标<code>i</code>存在寄存器<code>%rax</code>中，这一个改进大幅降低了访问指标<code>i</code>和数组元素<code>a[i]</code>和其他数组的时间。<code>simd0-O1.s</code>的代码非常符合我们思维，它使用<code>movss</code>从内存中取一个单精度数，使用<code>addss</code>和<code>mulss</code>执行单精度浮点数的加法和乘法。执行一遍计算后再做第二遍。</p>
<p>使用<code>-O2</code>优化和<code>-O1</code>对这个程序没有太大差异，我们略去。</p>
<h2 id="SIMD的第一尝试"><a href="#SIMD的第一尝试" class="headerlink" title="SIMD的第一尝试"></a>SIMD的第一尝试</h2><p>如果我们使用<code>-O3</code>级别优化，就会放发生某些不一样的事情，汇编代码见<code>code 2: simd0-O3.s</code><br><code>`</code>x86asm code 2: simd0-O3.s<br>main:<br>  movl $50000, %edx<br>.L2:<br>  xorl %eax, %eax<br>.L3:<br>  movaps b(%rax), %xmm0<br>  addps a(%rax), %xmm0<br>  addq $16, %rax<br>  mulps c-16(%rax), %xmm0<br>  movaps %xmm0, r-16(%rax)<br>  cmpq $400000, %rax<br>  jne .L3<br>  addss %xmm1, %xmm1<br>  subl $1, %edx<br>  jne .L2<br>  cvttss2si %xmm1, %eax<br>  ret</p>
<pre><code>和`code 1: simd0-O2.s`相比，`code 2: simd0-O3.s`代码启用了SSE指令集的SIMD指令，它使用完整的`xmm`寄存器，而不是低32位，进行浮点数的加法和乘法。其中，`movaps`从内存中取4个单精度浮点数放在`xmm`寄存器中，或者相反方向，`addps`和`mulps`分别对`xmm`寄存器中的4个单精度数据做加法和乘法。使用SSE指令，运行时间又降为`2s 612ms 38μs`。

## AVX2上场
虽然我们仍然可以使用参数让编译器自动向量化，比如`gcc -O3 -maxv2 -o simd1-avx2-O3.exe simd1.c`，但是这样的优化结果是不可预测的，因此在编程的时候使用适当的机制或约定引导编译器进行向量化，是更加稳健的方法。

### 内存对齐
将变量的存储地址对齐到8/16/32/64等整数的倍数，是某些指令的要求，同时可以使寻址更加有效。在GCC环境下，使用`__attribute__((aligned(__BIGGEST_ALIGNMENT__)))`修饰符引导编译器进行内存对齐。比如声明长度为N的float数组，对齐到64字节
```c 
float a[N] __attribute__((aligned(64)));
</code></pre><h3 id="向量数据类型"><a href="#向量数据类型" class="headerlink" title="向量数据类型"></a>向量数据类型</h3><p>在GCC环境下，可以声明基本数据类型<code>char int float double long</code>的数组作为向量，来引导编译器使用SIMD指令编译，比如下面的代码声明了一种8个float长的向量类型<code>v8f</code>，</p>
<pre><code class="c">typedef float v8f __attribute__((vector_size(32)));
</code></pre>
<p>向量数据类型可以使用运算符<code>+ - * / &amp; ^ | %</code>等进行逐元素运算，他们会被编译成相应的SIMD指令。</p>
<p>现在我们可以利用上面的技巧，来重写程序，确保我们使用了SIMD指令，见<code>code 3: simd1.c</code><br><code>`</code>c code 3: simd1.c</p>
<p>#include &lt;sys/time.h&gt;</p>
<p>#include &lt;stdio.h&gt;</p>
<p>#define N 100000</p>
<p>#define NTIMES 50000</p>
<p>#define ALIGN 64<br>typedef float v8f <strong>attribute</strong>((vector_size(32)));</p>
<p>#define VLEN (sizeof(v8f) / sizeof(float))</p>
<p>float a[N] <strong>attribute</strong>((aligned(ALIGN)));<br>float b[N] <strong>attribute</strong>((aligned(ALIGN)));<br>float c[N] <strong>attribute</strong>((aligned(ALIGN)));<br>float r[N] <strong>attribute</strong>((aligned(ALIGN)));</p>
<p>int main(void)<br>{<br>    v8f <em>va, </em>vb, <em>vc, </em>vr;<br>    int i, times, sum;<br>    struct timeval starttime, endtime;<br>    long s, ms, us, timeuse;<br>    gettimeofday(&amp;starttime, 0);</p>
<pre><code>/* workhorse code  */
for (times = 0; times &lt; NTIMES; times++)
{
    va = (v8f *)a;
    vb = (v8f *)b;
    vc = (v8f *)c;
    vr = (v8f *)r;
    for (i = 0; i &lt; N; i += VLEN){
        *vr = (*va + *vb) * (*vc);
        va++, vb++, vc++, vr++;
    }
    sum += sum;
}

/* elapsed time  */
gettimeofday(&amp;endtime, 0);
timeuse = 1000000 * (endtime.tv_sec - starttime.tv_sec) + 
endtime.tv_usec - starttime.tv_usec;
s = timeuse / 1000000;
ms = timeuse / 1000 % 1000;
us = timeuse % 1000;
printf(&quot;%ld s %ld ms %ld us\n&quot;, s, ms, us);

return sum;
</code></pre><p>}</p>
<pre><code>上面的程序使用指向向量数据类型`v8f`的指针来进行运算，这些操作可以很好的编译成SIMD指令。并且由于向量长度是8的整数倍，所以我们不用额外的操作。使用命令`gcc -mavx2 -O3 -S -o simd1-O3.s simd1.c`编译，得到和我们预想一样的汇编代码
```x86asm code 4: simd1-O3.s
main:
  xorl %eax, %eax
  movl $50000, %ecx
.L3:
  xorl %edx, %edx
.L2:
  vmovaps a(%rdx), %ymm1
  vaddps b(%rdx), %ymm1, %ymm0
  addq $32, %rdx
  vmulps c-32(%rdx), %ymm0, %ymm0
  vmovaps %ymm0, r-32(%rdx)
  cmpq $400000, %rdx
  jne .L2
  addl %eax, %eax
  subl $1, %ecx
  jne .L3
  vzeroupper
  ret
</code></pre><p>和<code>code 2: simd0-O3.s</code>不同的是，这里使用指令<code>vmovaps vaddps vmulps</code>对8个（组）float数据进行操作。虽然我们一顿操作，但是效率提升并不明显，原因是因为这个例子中，最费时的是内存的读写而不是计算加法和乘法。</p>
<p>我们换一个顺序，对于某个i，我们重复<code>NTIMES</code>次<code>r[i] = (a[i] + b[i]) * c[i]</code>操作，然后在进行下一个i，由于编译器优化总是会去掉一层循环，所以我们直接修改汇编代码如下<br><code>`</code>x86asm code 5: simd2-0.s<br>main:<br>.L2:<br>    movl    $50000, %eax<br>.L3:<br>    vmovaps    a(%rdx), %ymm1<br>    vaddps    b(%rdx), %ymm1, %ymm0<br>    vmulps    c(%rdx), %ymm0, %ymm0<br>    .p2align 4,,10<br>    addl    %ebx, %ebx<br>    vmovaps    %ymm0, r(%rdx)<br>    subl    $1, %eax<br>    jne    .L3<br>    addq    $32, %rdx<br>    cmpq    $400000, %rdx<br>    jne    .L2<br>    xorl    %edx, %edx<br>    vzeroupper<br>    ret</p>
<pre><code>
用命令`gcc -o simd2-0.exe simd2-0.s`将汇编指令链接成二进制程序。虽然只是调换了两个循环的顺序，操作也没有少一个，但是由于L1/2/3 cache的存在，`code 5`a显著降低了访问内存的次数，执行时间仅为`0s 634ms 562μs`，验证了我们上面关于效率瓶颈的论断。

如果我们显式地先读一次数据到寄存器中，做`NTIMES`次计算，最后再写到内存中，这样就避免了多次读写内存的操作。汇编代码如下
```x86asm code 6: simd2-1.s
main:
.L2:
    movl    $50000, %eax
    vmovaps    a(%rdx), %ymm1
    vmovaps    b(%rdx), %ymm2
    vmovaps    c(%rdx), %ymm3
.L3:
    vaddps    %ymm2, %ymm1, %ymm0
    vmulps    %ymm3, %ymm0, %ymm0
    .p2align 4,,10
    addl    %ebx, %ebx
    vmovaps    %ymm0, r(%rdx)
    subl    $1, %eax
    jne    .L3
    addq    $32, %rdx
    cmpq    $400000, %rdx
    jne    .L2
    xorl    %edx, %edx
    vzeroupper
    ret
</code></pre><p>最后优化的程序执行时间为<code>0s 324ms 504μs</code>。和最初的13.8s相比，这个速度快了40多倍，虽然主要功劳并不归功于SIMD指令，但是合理的SIMD向量化有助于我们减少内存的访问，从而为程序加速。</p>

	

	
		<span class="different-posts"><a href="/2018/11/03/SIMD指令优化/" onclick="window.history.go(-1); return false;">⬅️ Go back </a></span>

	

</article>

	</main>

	<footer class="footer">
	<div class="footer-content">
		
	      <div class="footer__element">
	<p>Hi there, <br>welcome to my Blog glad you found it. Have a look around, will you?</p>
</div>

	    
	      <div class="footer__element">
	<h5>Check out</h5>
	<ul class="footer-links">
		<li class="footer-links__link"><a href="/archives">Archive</a></li>
		
		  <li class="footer-links__link"><a href="/atom.xml">RSS</a></li>
	    
		<li class="footer-links__link"><a href="/about">about page</a></li>
		<li class="footer-links__link"><a href="/tags">Tags</a></li>
		<li class="footer-links__link"><a href="/categories">Categories</a></li>
	</ul>
</div>

	    

		<div class="footer-credit">
			<span>© 2018 von Weber | Powered by <a href="https://hexo.io/">Hexo</a> | Theme <a href="https://github.com/HoverBaum/meilidu-hexo">MeiliDu</a></span>
		</div>

	</div>


</footer>



</body>

</html>
