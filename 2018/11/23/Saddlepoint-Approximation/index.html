<!DOCTYPE html>
<html>

<head><meta name="generator" content="Hexo 3.8.0">
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<meta name="theme-color" content="#33474d">
	<title>Saddlepoint Approximation | Von Weber&#39;s Blog</title>
	<link rel="stylesheet" href="/css/style.css">
	
      <link rel="alternate" href="/atom.xml" title="Von Weber&#39;s Blog" type="application/atom+xml">
	
	
	<script type="text/x-mathjax-config">
		MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
	</script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML" async></script>

</head>

<body>

	<header class="header">
		<nav class="header__nav">
			
				<a href="/archives" class="header__link">Archive</a>
			
				<a href="/tags" class="header__link">Tags</a>
			
				<a href="/atom.xml" class="header__link">RSS</a>
			
		</nav>
		<h1 class="header__title"><a href="/">Von Weber&#39;s Blog</a></h1>
		<h2 class="header__subtitle">No models are correct, but some are more elegant than others.</h2>
	</header>

	<main>
		<article>
	
		<h1>Saddlepoint Approximation</h1>
	
	<div class="article__infos">
		<span class="article__date">2018-11-23</span><br>
		
		
			<span class="article__tags">
			  	<a class="article__tag-link" href="/tags/积分计算/">积分计算</a> <a class="article__tag-link" href="/tags/统计/">统计</a> <a class="article__tag-link" href="/tags/统计计算/">统计计算</a>
			</span>
		
	</div>

	

	
		<p>和Edgeworth展开相比，鞍点近似是更加精细的分布近似方法，鞍点近似同时适用于连续和离散的分布。在许多极端的条件下，鞍点近似都表现出惊人的精度。鞍点近似有许多角度的理解，然而下面的推导展示了鞍点近似和Edgeworth的关系，以及它为什么具有高精度。</p>
<h2 id="Tilted-Exponential-Families"><a href="#Tilted-Exponential-Families" class="headerlink" title="Tilted Exponential Families"></a>Tilted Exponential Families</h2><p>设 $f(x)$ 是一个密度函数，在区间 $(a,b)$ 具有矩母函数 $M(s) = E e^{sX} $ 和累量母函数 $ K(s) = \log M(s) $。则下列指数分布族称为 tilted 正则指数族 $$ f(x;s) = \exp \{ sx - K(s) \} f(x), \qquad s \in (a,b) $$<br>$f(x;s)$ 称作 s-tilted 密度，用 $X_s$ 表示服从此密度的一个随机变量。容易推导 $X_s$ 的 均值和方差满足<br>$$ E(X_s) = K’(s)$$  $$ Var(X_s) = K’’(s)$$<br>以及 $X_s$ 的高阶标准化累量<br>$$ \kappa_i(s) = E \left( {X_s -\mu_s \over \sigma_s} \right)^i =<br>{K^{(i)}(s) \over \{ K’’(s) \}^{i/2} }, \qquad i \geq 3 $$</p>
<h2 id="Saddlepoint-Approximation"><a href="#Saddlepoint-Approximation" class="headerlink" title="Saddlepoint Approximation"></a>Saddlepoint Approximation</h2><p>由 tilted 指数族定义可知<br>$$ f(x) \equiv \exp \{ K(s) -sx \} f(x;s), \qquad \forall s \in (a,b) $$<br>注意这里是对任意的 s，两边都是一样的密度函数。所以我们可以针对不同的 x，选择不同的 s，使近似效果达到最佳。</p>
<p>考虑 $ f(x;s) $ 的Edgeworth 展开<br>$$ f(x;s) = \phi \left( {x -\mu_s \over \sigma_s} \right) \left\{ 1 + {\kappa_{3}(s) \over 6 }  \left[ \left( {x -\mu_s \over \sigma_s} \right)^3 - 3 \left( {x -\mu_s \over \sigma_s} \right)  \right] + O \left( {1 \over n} \right) \right\} $$<br>对于固定的 x，若选择s，使得 $\mu_s =x$，则在x点上的近似具有 $O(1/n)$ 的精度。现在对不同的x，我们始终选择 $\hat s$ 满足<br>$$  K’(\hat s(x)) = x $$<br>从而可以使 $O(1/n)$ 的精度是全局的。上面的方程被称作鞍点方程。将 $ f(x;s) $ 的近似带入到 $ f(x) $ 中<br>$$ f(x) \approx \hat f(x) = {1 \over \sqrt{2 \pi K’’(\hat s (x)) }} \exp \{ K(\hat s(x)) -\hat s(x)x \} $$<br>上式称为 $ f(x) $ 的（一阶）鞍点近似。要注意的是 $ \hat f(x) $ 并不是真正的密度函数，因为<br>$$ c := \int_{\Bbb R} \hat f(x) dx \neq 1   $$<br>正规化的鞍点近似密度函数为<br>$$ \bar f(x) = c^{-1} \hat f(x), \qquad x \in \mathcal X $$</p>
<h2 id="连续分布的鞍点近似"><a href="#连续分布的鞍点近似" class="headerlink" title="连续分布的鞍点近似"></a>连续分布的鞍点近似</h2><p>设 $X_i, i \in \Bbb{N}$ 是独立同分布的连续随机变量，具有累量母函数 $K(s)$。则均值 $ \bar X =1/n \sum_{i=1}^n X_i$ 密度函数的鞍点近似为<br>$$ \hat f _{\bar X}(x)  = \sqrt{ { n \over 2 \pi K’’(\hat s (x)) } } \exp \{ K( \hat s(x)) -\hat s(x)x \} $$</p>
<p>$X$ 分布的函数的鞍点近似为<br>$$ \hat F_{\bar X}(x) = \begin{cases}<br>    \Phi(\hat w) + \phi(\hat w) \left( {1 \over \hat w} - {1 \over \hat u} \right) &amp; \text{if  }x \neq \mu \\<br>    {1 \over 2} + { K’’’(0) \over 6 \sqrt{2} \pi K’’(0)^{3/2} } &amp; \text{if  }x = \mu<br>\end{cases} $$<br>其中<br>$$\begin{align}<br>\hat w &amp;= \text{sgn}(\hat s) \sqrt{ 2 \{ \hat s x -K(\hat s) \} } \\<br>\hat u &amp;= \hat s \sqrt{ K’’(\hat s) }<br>\end{align} $$<br>$\Phi(\cdot),\phi(\cdot) $ 分别为标准正态分布的分布函数和密度函数，$\hat s$ 是鞍点方程 $K’(s) =x $ 的解。</p>
<h2 id="离散分布的鞍点近似"><a href="#离散分布的鞍点近似" class="headerlink" title="离散分布的鞍点近似"></a>离散分布的鞍点近似</h2><p>设 $X$ 是整数集 $\Bbb{Z}$ 上的随机变量， $p(k)$ 是其质量函数，则 $p(k) $ 具有鞍点近似<br>$$ \hat p(k) = {1 \over \sqrt{ 2 \pi K’’(\hat s) }} \exp \{  K(\hat s) - \hat s k  \} $$<br>其中 $\hat s$ 是鞍点方程 $K’(\hat s) = k, \quad k \in \mathcal{I_X}  $， $\mathcal{I_X}  $ 是 supp X 延展的内点集。</p>
<p>定义 $ k^- =k-1/2 \in \mathcal{I_X} $ 是 k的偏置，$\hat s$ 是鞍点方程 $K’(\hat s) = k^-$ 的解，则$X$ 生存函数的（第二连续性矫正）鞍点近似为<br>$$ \hat{Pr}(X \geq k) = \begin{cases}<br>    1 - \Phi(\hat w) - \phi(w)(1/2 - 1/u) &amp; \text{if } k^- \neq \mu \\<br>    1/2 - { K’’’(0) \over 6 \sqrt{2} K’’(0)^{3/2} } &amp; \text{if  } k^- = \mu<br>\end{cases}  $$<br>其中<br>$$\begin{align}<br>    \hat w &amp;= \text{sgn}(\hat s) \sqrt{2 \{ \hat s k^- -K(\hat s)  \}} \\<br>    \hat u &amp;= 2 \text{sinh}(\hat s/2) \sqrt{K’’(\hat s)}<br>\end{align}$$</p>
<h2 id="Sum-of-Binomials"><a href="#Sum-of-Binomials" class="headerlink" title="Sum of Binomials"></a>Sum of Binomials</h2><p>设 $X_i,i=1,2,3$ 是独立随机变量，$X_i \sim \text{Binomial}(m_i,\theta_i) $，其中 $ m_i = 8-2i, \theta_i = 2^i/30 $。现在考虑 $ X = \sum_i X_i $ 的质量函数和分布函数。相信这样的事情能让几乎每一个人抓狂。</p>
<p>$X$ 的CGF为<br>$$ K(s) = 2 \sum_{i=1}^3 (4-i) \log \left\{ {2^i \over 30} (e^s -1) +1\right \}, \quad s \in \Bbb{R} $$<br>对应的鞍点方程为<br>$$ K’(s) = {6\hat t \over \hat t +14} + {8\hat t \over 2\hat t +13} +{8\hat t \over 4\hat t +11} $$<br>其中 $ \hat t = \exp(\hat s) $。下表展示了上述的鞍点近似质量函数 $\hat p(k)$，和对应的归一化鞍点近似 $ \bar p(k) $</p>
<table>
<thead>
<tr>
<th>$k$</th>
<th>$p(k) $</th>
<th>$ \hat p(k) $</th>
<th>$ \bar p(k) $</th>
<th>$ \text{Poisson}(\mu) $</th>
</tr>
</thead>
<tbody>
<tr>
<td>$1$</td>
<td>$.3552$</td>
<td>$.3845$</td>
<td>$.3643$</td>
<td>$.3384$</td>
</tr>
<tr>
<td>$3$</td>
<td>$.1241 $</td>
<td>$.1273$</td>
<td>$.1206$</td>
<td>$.1213$</td>
</tr>
<tr>
<td>$5$</td>
<td>$.0^2 7261$</td>
<td>$.0^2 7392$</td>
<td>$.0^2 7004$</td>
<td>$.01305$</td>
</tr>
<tr>
<td>$7$</td>
<td>$.0^3 1032$</td>
<td>$.0^3 1052$</td>
<td>$.0^4 9963$</td>
<td>$.0^3 6682$</td>
</tr>
<tr>
<td>$9$</td>
<td>$.0^6 3633$</td>
<td>$.0^6 3738$</td>
<td>$.0^6 3541$</td>
<td>$.0^4 1996$</td>
</tr>
<tr>
<td>$11$</td>
<td>$.0^9 2279$</td>
<td>$.0^9 2472$</td>
<td>$.0^9 2342$</td>
<td>$.0^6 3904$</td>
</tr>
</tbody>
</table>
<p>在k=1,3时，Poisson近似差强人意，更大的k时，Poisson近似就稀烂了。而（对这个问题）鞍点近似在全局都保持着惊人的精度，注意 $ 0 \leq X \leq 12 $。通常情况下，对密度进行归一化能得到更好的近似，但是归一化常数的计算可能并不直接。</p>
<p>另一方面，对于分布函数，下表展示了鞍点近似的生存函数（右尾概率）</p>
<table>
<thead>
<tr>
<th>$k$</th>
<th>$Pr(X \geq k) $</th>
<th>$ \hat {Pr}(X \geq k) $</th>
<th>$ \text{Poisson}(\mu) $</th>
</tr>
</thead>
<tbody>
<tr>
<td>$1 $</td>
<td>$.7994$</td>
<td>$.8064$</td>
<td>$.7693$</td>
</tr>
<tr>
<td>$2 $</td>
<td>$.5558$</td>
<td>$.5531$</td>
<td>$.4310$</td>
</tr>
<tr>
<td>$3$</td>
<td>$.1687$</td>
<td>$.1695$</td>
<td>$.1828$</td>
</tr>
<tr>
<td>$4$</td>
<td>$.04464$</td>
<td>$.04483$</td>
<td>$.06153$</td>
</tr>
<tr>
<td>$5$</td>
<td>$.0^2 8397$</td>
<td>$.0^2 8428$</td>
<td>$.01705$</td>
</tr>
<tr>
<td>$6$</td>
<td>$.0^2 1137$</td>
<td>$.0^2 1140$</td>
<td>$.0^2 4003$</td>
</tr>
<tr>
<td>$7$</td>
<td>$.0^3 1109$</td>
<td>$.0^3 1112$</td>
<td>$.0^3 8141$</td>
</tr>
<tr>
<td>$8$</td>
<td>$.0^5 7732$</td>
<td>$.0^5 7742$</td>
<td>$.0^3 1458$</td>
</tr>
<tr>
<td>$9$</td>
<td>$.0^6 3753$</td>
<td>$.0^6 3751$</td>
<td>$.0^4 2334$</td>
</tr>
<tr>
<td>$10$</td>
<td>$.0^7 1205$</td>
<td>$.0^7 1199$</td>
<td>$.0^5 3372$</td>
</tr>
<tr>
<td>$11$</td>
<td>$.0^9 2299$</td>
<td>$.0^9 2266 $</td>
<td>$.0^6 4441$</td>
</tr>
<tr>
<td>$12$</td>
<td>$.0^{11} 1973$</td>
<td>$.0^{11 }1861$</td>
<td>$.0^7 5373$</td>
</tr>
</tbody>
</table>
<h2 id="Gumbel-0-1-Distribution"><a href="#Gumbel-0-1-Distribution" class="headerlink" title="Gumbel(0,1) Distribution"></a>Gumbel(0,1) Distribution</h2><p>设 $ X \sim \text{Gumbel}(0,1) $，具有分布函数 CDF<br>$$ F(x) = e^{- e^{-x}}, \qquad x \in (-\infty, \infty) $$<br>和累量母函数 CGF<br>$$ K(s) = \log \Gamma (1-s), \qquad s \in (-\infty, 1) $$<br>鞍点方程为<br>$$ -\digamma(1- \hat s) = x, \qquad s &lt; 1 $$<br>其中 $ \digamma(\cdot) $ 是双gamma函数 (digamma, gamma 函数的一阶导数)<br>鞍点近似为<br>$$ \hat f(x) = {1 \over \sqrt{2 \pi K’’(\hat s (x)) }} \exp \{ K(\hat s(x)) -\hat s(x)x \} $$<br>正规化的鞍点近似为<br>$$ \bar f(x) = c^{-1} \hat f(x) $$<br>其中<br>$$ c = \int_{\Bbb R} \hat f(x) dx \approx 0.9792  $$</p>
<p>另一方面，$ EX = \gamma := \lim_{n \rightarrow \infty} (-\log n + \sum_{k=1}^n 1/k) \approx 0.5772 $ 是 Euler–Mascheroni 常数， $ Var X = \pi^2/6$，高阶标准化累量满足<br>$$ \kappa_n = { K^{(n)} \over \sigma^n } = (n-1)! \zeta(n) $$<br>其中 $\zeta (s) = \sum_{n=1}^{\infty} n^{-s} $ 是 Riemann zeta 函数。特别地 $\kappa_3 \approx  1.14, \kappa_4 \approx 2.40 $。$X$ 的Edgeworth近似为<br>$$ f(x) = \phi(z) \left[ 1+ {\kappa_3 \over 6 } H_3(z) +<br>\left\{ {\kappa_4 \over 24}H_4(z) + {\kappa_3^2 \over 72}H_6(z) \right\} + O(n^{-3/2})  \right] $$<br>其中 $\phi(\cdot)$ 是标准正态分布的密度函数，$z=(x-\mu)/\sigma $，$H_k(\cdot)$ 是 Hermite 多项式。</p>
<p>下图展示了鞍点近似和 Edgeworth 近似，鞍点近似的效果非常惊人，正规化的鞍点近似更是（视觉上）与真实的密度无法区分。</p>
<p><figure class="figure"><img src="/img/saddlepoint-1.svg" alt="图1. Gumbel(0,1)分布的鞍点近似"><figcaption class="figure__caption">图1. Gumbel(0,1)分布的鞍点近似</figcaption></figure></p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">g = <span class="keyword">function</span>(s, x) &#123;</span><br><span class="line">  -digamma(<span class="number">1</span> - s) - x</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># root of saddlepoint equation</span></span><br><span class="line">saddleEq = <span class="keyword">function</span>(x) &#123;</span><br><span class="line">  sapply(x, <span class="keyword">function</span>(t)</span><br><span class="line">    uniroot(g, c(-<span class="number">1e6</span>, <span class="number">0.9999</span>), tol = <span class="number">1e-6</span>, x = t)$root)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># saddlepoint density</span></span><br><span class="line">f_saddle = <span class="keyword">function</span>(x) &#123;</span><br><span class="line">  s = saddleEq(x)</span><br><span class="line">  <span class="number">1</span> / sqrt(<span class="number">2</span> * pi * trigamma(<span class="number">1</span> - s)) * exp(lgamma(<span class="number">1</span> - s) - s * x)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">c = integrate(f_saddle,-<span class="number">10</span>, <span class="number">10</span>)$value</span><br><span class="line"></span><br><span class="line"><span class="comment"># normalized saddlepoint density</span></span><br><span class="line">f_norm_saddle = <span class="keyword">function</span>(x) &#123;</span><br><span class="line">  f_saddle(x) / c</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Hermite polynomials</span></span><br><span class="line">H3 = <span class="keyword">function</span>(x) (x ^ <span class="number">3</span> - <span class="number">3</span> * x)</span><br><span class="line">H4 = <span class="keyword">function</span>(x) (x ^ <span class="number">4</span> - <span class="number">6</span> * x ^ <span class="number">2</span> + <span class="number">3</span>)</span><br><span class="line">H6 = <span class="keyword">function</span>(x) (x ^ <span class="number">6</span> - <span class="number">15</span> * x ^ <span class="number">4</span> + <span class="number">45</span> * x ^ <span class="number">2</span> - <span class="number">15</span>)</span><br><span class="line"></span><br><span class="line">mu = <span class="number">0.577215665</span></span><br><span class="line">sigma = sqrt(pi * pi / <span class="number">6</span>)</span><br><span class="line">k3 = factorial(<span class="number">2</span>) * <span class="number">1.202057</span> / sigma ^ <span class="number">3</span></span><br><span class="line">k4 = factorial(<span class="number">3</span>) * <span class="number">1.082323</span> / sigma ^ <span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># first-order Edgeworth</span></span><br><span class="line">f_Edge1 = <span class="keyword">function</span>(x) &#123;</span><br><span class="line">  z = (x - mu) / sigma</span><br><span class="line">  dnorm(z) * (<span class="number">1</span> + k3 * H3(z) / <span class="number">6</span>) / sigma</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># second-order Edgeworth</span></span><br><span class="line">f_Edge2 = <span class="keyword">function</span>(x) &#123;</span><br><span class="line">  z = (x - mu) / sigma</span><br><span class="line">  f_Edge1(x) + (k4 * H4(z) / <span class="number">24</span> + k3 ^ <span class="number">2</span> * H6(z) / <span class="number">72</span>) * dnorm(z) / sigma</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># density of Gumbel(0,1)</span></span><br><span class="line">f_Gumbel = <span class="keyword">function</span>(x) &#123;</span><br><span class="line">  exp(-x - exp(-x))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">label = c(</span><br><span class="line">  <span class="string">'Exact'</span>,</span><br><span class="line">  <span class="string">'Saddlepoint'</span>,</span><br><span class="line">  <span class="string">'Normalized Saddlepoint'</span>,</span><br><span class="line">  <span class="string">'First-order Edgeworth'</span>,</span><br><span class="line">  <span class="string">'Second-order Edgeworth'</span></span><br><span class="line">)</span><br><span class="line">x = seq(-<span class="number">3</span>, <span class="number">5</span>, <span class="number">1e-2</span>)</span><br><span class="line">data = data.frame(</span><br><span class="line">  density = c(</span><br><span class="line">    f_Gumbel(x),</span><br><span class="line">    f_saddle(x),</span><br><span class="line">    f_norm_saddle(x),</span><br><span class="line">    f_Edge1(x),</span><br><span class="line">    f_Edge2(x)</span><br><span class="line">  ),</span><br><span class="line">  x = rep(x, length(label)),</span><br><span class="line">  Approximations = rep(label, each = length(x))</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">ggplot(data, aes(x, density, color = Approximations)) +</span><br><span class="line">  scale_colour_manual(</span><br><span class="line">    breaks = label,</span><br><span class="line">    values = c(<span class="string">'#000000'</span>, <span class="string">'#e41a1c'</span>, <span class="string">'#377eb8'</span>, <span class="string">'#4daf4a'</span>, <span class="string">'#984ea3'</span>)</span><br><span class="line">  ) +</span><br><span class="line">  theme(legend.position = c(<span class="number">0.85</span>, <span class="number">0.75</span>)) +</span><br><span class="line">  geom_line(alpha = <span class="number">0.6</span>)</span><br></pre></td></tr></table></figure>
	

	
		<span class="different-posts"><a href="/2018/11/23/Saddlepoint-Approximation/" onclick="window.history.go(-1); return false;">⬅️ Go back </a></span>

	

</article>

	</main>

	<footer class="footer">
	<div class="footer-content">
		
	      <div class="footer__element">
	<p>Hi there, <br>welcome to my Blog glad you found it. Have a look around, will you?</p>
</div>

	    
	      <div class="footer__element">
	<h5>Check out</h5>
	<ul class="footer-links">
		<li class="footer-links__link"><a href="/archives">Archive</a></li>
		
		  <li class="footer-links__link"><a href="/atom.xml">RSS</a></li>
	    
		<li class="footer-links__link"><a href="/about">about page</a></li>
		<li class="footer-links__link"><a href="/tags">Tags</a></li>
		<li class="footer-links__link"><a href="/categories">Categories</a></li>
	</ul>
</div>

	    

		<div class="footer-credit">
			<span>© 2018 von Weber | Powered by <a href="https://hexo.io/">Hexo</a> | Theme <a href="https://github.com/HoverBaum/meilidu-hexo">MeiliDu</a></span>
		</div>

	</div>


</footer>



</body>

</html>
